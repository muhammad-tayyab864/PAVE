{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.15 (you have 1.4.11). Upgrade using: pip install --upgrade albumentations\n"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "import torch \n",
    "import pandas as pd\n",
    "import random\n",
    "import warnings \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from models.space_net import SPACE\n",
    "from models.race import RACE, ACE\n",
    "from models.hdrnet import PICE_B\n",
    "from utils import decompose_imgs, compose_imgs\n",
    "from ssim_map import pos_similarity_ratio\n",
    "from saliency_losses import nss, corr_coeff, kld_loss, log_softmax, softmax\n",
    "from utils import contrast_loss_G, contrast_loss_L, R_imgs, R_sclr, EME\n",
    "from ISFDataset import ISFDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from kornia.losses.ssim import ssim_loss\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1080, 1920])\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"./test_images/OutdoorManMade_004.jpg\") \n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "orig_img = img.copy()\n",
    "img = torch.from_numpy(img).permute(2,0,1).unsqueeze(0) / 255. \n",
    "y, cbcr = decompose_imgs(img)\n",
    "\n",
    "gamma = 2.2\n",
    "k = 0.6\n",
    "R = 1 - k ** gamma\n",
    "y_R = y * k\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_space = SPACE(apply_center_bias=True, apply_gfcorrection=True, apply_len=True)\n",
    "model_race = RACE()\n",
    "model_ace = ACE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MEASURE LATENCY CPU\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "def measure_latency_cpu_usage(model, test_inputs, R=0):\n",
    "    # move model and input to cpu\n",
    "    model = model.to(\"cpu\")\n",
    "    test_inputs = test_inputs.to(\"cpu\")\n",
    "    process = psutil.Process()\n",
    "    cpu_start = process.cpu_percent()\n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "        _ = model(test_inputs, R=R)\n",
    "    end = time.time()\n",
    "    cpu_end = process.cpu_percent()\n",
    "    latency = end - start\n",
    "    cpu_usage = cpu_end - cpu_start\n",
    "    return latency, cpu_usage\n",
    "\n",
    "history_ltc = []\n",
    "for i in range(50):\n",
    "    ltc, _ = measure_latency_cpu_usage(model_ace, y, R)\n",
    "    history_ltc.append(ltc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7074264478683472 0.11476966168500274\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(history_ltc), np.std(history_ltc)) # in second unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.207590465545653 6.836386203871888\n"
     ]
    }
   ],
   "source": [
    "### MEASURE LATENCY GPU\n",
    "# move the model to GPU\n",
    "def measure_latency_gpu(model, test_inputs, R=0):\n",
    "   model = model.to(\"cuda\")\n",
    "   test_inputs = test_inputs.to(\"cuda\")\n",
    "   starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "   repetitions = 50\n",
    "   timings=np.zeros((repetitions,1))\n",
    "   #GPU-WARM-UP\n",
    "   for _ in range(10):\n",
    "      _ = model(test_inputs, R=R)\n",
    "   # MEASURE PERFORMANCE\n",
    "   with torch.no_grad():\n",
    "      for rep in range(repetitions):\n",
    "         starter.record()\n",
    "         _ = model(test_inputs, R=R)\n",
    "         ender.record()\n",
    "         # WAIT FOR GPU SYNC\n",
    "         torch.cuda.synchronize()\n",
    "         curr_time = starter.elapsed_time(ender)\n",
    "         timings[rep] = curr_time\n",
    "   mean_syn = np.sum(timings) / repetitions\n",
    "   std_syn = np.std(timings)\n",
    "   print(mean_syn, std_syn)\n",
    "   \n",
    "measure_latency_gpu(model_ace, y, R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PERFORM THE TWO TASKS FOR DIFFERENT INPUT RESOLUTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 480, 848])\n",
      "torch.Size([1, 1, 720, 1280])\n",
      "torch.Size([1, 1, 1080, 1920])\n",
      "torch.Size([1, 1, 1556, 2048])\n"
     ]
    }
   ],
   "source": [
    "img_480 = cv2.resize(orig_img, (848, 480))\n",
    "img_720 = cv2.resize(orig_img, (1280, 720))\n",
    "img_1080 = orig_img\n",
    "img_2k = cv2.resize(orig_img, (2048, 1556))\n",
    "img_480 = torch.from_numpy(img_480).permute(2,0,1).unsqueeze(0) / 255. \n",
    "img_720 = torch.from_numpy(img_720).permute(2,0,1).unsqueeze(0) / 255. \n",
    "img_1080 = torch.from_numpy(img_1080).permute(2,0,1).unsqueeze(0) / 255. \n",
    "img_2k = torch.from_numpy(img_2k).permute(2,0,1).unsqueeze(0) / 255. \n",
    "y_480, _ = decompose_imgs(img_480)\n",
    "y_1080, _ = decompose_imgs(img_1080)\n",
    "y_720, _ = decompose_imgs(img_720)\n",
    "y_2k, _ = decompose_imgs(img_2k)\n",
    "print(y_480.shape)\n",
    "print(y_720.shape)\n",
    "print(y_1080.shape)\n",
    "print(y_2k.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL 0\n",
      "==== CPU TIME FOR INPUT torch.Size([1, 1, 480, 848])\n",
      "0.11786510944366455 0.03009372474663\n",
      "==== CPU TIME FOR INPUT torch.Size([1, 1, 720, 1280])\n",
      "0.2811474561691284 0.037067512476026104\n",
      "==== CPU TIME FOR INPUT torch.Size([1, 1, 1080, 1920])\n",
      "0.624513578414917 0.04705529130354958\n",
      "==== CPU TIME FOR INPUT torch.Size([1, 1, 1556, 2048])\n",
      "1.143249261379242 0.07141222170426291\n",
      "MODEL 1\n",
      "==== CPU TIME FOR INPUT torch.Size([1, 1, 480, 848])\n",
      "0.1412052631378174 0.042450912000047046\n",
      "==== CPU TIME FOR INPUT torch.Size([1, 1, 720, 1280])\n",
      "0.28241515159606934 0.025034656682280682\n",
      "==== CPU TIME FOR INPUT torch.Size([1, 1, 1080, 1920])\n",
      "0.6356225967407226 0.04471946831959279\n",
      "==== CPU TIME FOR INPUT torch.Size([1, 1, 1556, 2048])\n",
      "1.1820658683776855 0.10633202826956754\n",
      "MODEL 2\n",
      "==== CPU TIME FOR INPUT torch.Size([1, 1, 480, 848])\n",
      "0.07029536962509156 0.04150862819000167\n",
      "==== CPU TIME FOR INPUT torch.Size([1, 1, 720, 1280])\n",
      "0.07534888982772828 0.029960919667115015\n",
      "==== CPU TIME FOR INPUT torch.Size([1, 1, 1080, 1920])\n",
      "0.08960298299789429 0.019998148555502242\n",
      "==== CPU TIME FOR INPUT torch.Size([1, 1, 1556, 2048])\n",
      "0.08542163372039795 0.014706765657625569\n"
     ]
    }
   ],
   "source": [
    "img_list = [y_480, y_720, y_1080, y_2k]\n",
    "model_list = [model_ace, model_race, model_space]\n",
    "\n",
    "for i, model in enumerate(model_list):\n",
    "    print(f\"MODEL {i}\")\n",
    "    for img in img_list:\n",
    "        print(f\"==== CPU TIME FOR INPUT {img.shape}\")\n",
    "        history_ltc = []\n",
    "        for i in range(20):\n",
    "            ltc, _ = measure_latency_cpu_usage(model, img, R)\n",
    "            history_ltc.append(ltc)\n",
    "        print(np.mean(history_ltc), np.std(history_ltc)) # in second unit\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oled",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
